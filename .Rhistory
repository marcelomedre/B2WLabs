identical(answer, query1)
identical(answer, query2)
identical(answer, query3)
identical(answer, query4)
query1 <- sqldf("select unique AGEP from acs")
View(query2)
library(XML)
library(httr)
?nchar
library(XML)
library(httr)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
html <- readLines(con)
close(con)
answer <- c(nchar(html[10]), nchar(html[20]), nchar(html[30]), nchar(html[100]))
answer
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url, destfile = "data.for", method = "auto")
data <- read.fwf(data.for)
?read.fwf
lines <- readLines(url, n=10)
widths <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler",
"sstaNino12", "filler", "sstNino3", "filler", "sstaNino3",
"filler", "sstNino34", "filler", "sstaNino34", "filler",
"sstNino4", "filler", "sstaNino4")
data <- read.fwf(data.for, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf(url, widths = widths, header = FALSE, skip = 4, col.names = colNames)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
View(data)
answer <- sum(data[,4])
answer
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, col.names = colNames)
View(data)
data <- read.fwf("data.for", widths = widths, header = FALSE, skip = 4, col.names = colNames)
?grep
d <- d[, grep("^[^filler]", names(d))]
d <- d[, grep("^[^filler]", names(data))]
data <- data[, grep("^[^filler]", names(data))]
sum(d[, 4])
sum(data[, 4])
View(data)
answer <- sum(data[,4])
answer
86.83*3
[0-9]+ (.*)[0-9]+
## Working with dates
d1 = date()
d1
class(d1)
s2 = Sys.Date()
class(d2)
d2 = Sys.Date()
class(d2)
format(d2, "%a" "%b" %c"")
format(d2, "%a "%b %c")
format(d2, "%a "%b %d")
format(d2, "%a "%b %d")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
format(d2, "%a "%b %y")
x=c("1jan1960", "2jan1960", "31mar1960", "30jul1960")
z= as.Date(x, "%d%b%Y")
z
z[1]-z[2]
as.numeric(z[1-z[4]])
as.numeric(z[1]-z[4]])
as.numeric(z[1]-z[2]])
as.numeric(z[1]-z[2])
as.numeric(z[1]-z[4])
weedays(d2)
weekdays(d2)
months(d2)
julian(d2)
install.packages("lubridate")
library(lubridate)
ymd("20140108")
mdy("08/08/2015")
dmy("14/08/1988")
ymd_hms("14/08/1988 10:15:33")
ymd_hms("14-08-1988 10:15:33")
ymd_hms("2014-08-19 10:15:33")
ymd_hms("2014-08-19 10:15:33", tz = "Pacific/Auckland")
x=dmy(c("1jan1960", "2jan1960", "31mar1960", "30jul1960"))
wday(x[1])
wday(x[1], label = TRUE)
library(dplyr)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
if(file.exists("./data")){dir.create("./data")}
download.file(fileUrl, destfile = ".data/idaho_survey.csv", method = "auto")
download.file(fileUrl, destfile = ".idaho_survey.csv", method = "auto")
library(data.table)
getwd()
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE)
dataIdaho <- data.table(read.csv("idaho_survey.csv", stringsAsFactors = FALSE))
View(dataIdaho)
?strsplit
names(dataIdaho)
names <- names(dataIdaho)
strsplit(names, "wgtp")
strsplit(names, wgtp)
splittedData <- strsplit(names, "wgtp")
splittedData[123]
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl2, destfile = "GDP.csv", method = "auto")
dataGDP <- data.table(read.csv("GDP.csv", stringsAsFactors = FALSE))
View(dataGDP)
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, stringsAsFactors = FALSE))
select(dataGDP, c("X", "X1", "X3", "X4"))
select(dataGDP, c(1, 2, 4, 5))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
?colnames
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
dataGDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP <- select(dataGDP, c(1, 2, 4, 5))
colnames(dataGDP) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP)
dataGDP$numGDP <- as.numeric(gsub(",","",dataGDP$GDP))
average <- mean(dataGDP$numGDP)
average
?grep
grep("United$",Country), 3
grep("United$",Country)
grep("United$", dataGDP$Country)
grep("*United$", dataGDP$Country)
grep("^United",dataGDP$Country)
grep("^United",dataGDP$Country)
length(grep("United$", dataGDP$Country))
length(grep("*United$", dataGDP$Country))
length(grep("^United",dataGDP$Country))
length(grep("^United",dataGDP$Country))
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
fileUrl3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl3, destfile = "GDP_2.csv", method = "auto")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl4, destfile = "Educ.csv", method = "auto")
dataGDP2 <- data.table(read.csv("GDP.csv", skip = 4, nrows = 190, stringsAsFactors = FALSE))
dataGDP2 <- select(dataGDP2, c(1, 2, 4, 5))
colnames(dataGDP2) <- c("CountryCode", "RankGDP", "Country", "GDP")
names(dataGDP2)
dataEduc <- data.table(read.csv("Educ.csv", stringsAsFactors = FALSE))
View(dataEduc)
View(dataGDP)
View(dataEduc)
View(dataGDP2)
View(dataEduc)
?merge
dataEduc <- dataEduc[,c("CountryCode", "Special.Notes")]
fullData <- merge(dataGDP2,dataEduc, by.x = CountryCode, by.y = CountryCode)
fullData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
View(fullData)
mergedData <- merge(dataGDP2,dataEduc, by.x = "CountryCode", by.y = "CountryCode")
?grep
?grpl
?grepl
length(grep("[Ff]iscal year end(*/)+ June" ), mergedData$Special.Notes)
length(grep("[Ff]iscal year end(*/)+ June", mergedData$Special.Notes))
length(grep("[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end: (*/)+June", mergedData$Special.Notes))
length(grep("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
length(grepl("^[Ff]iscal year end:(*/)+June", mergedData$Special.Notes))
View(mergedData)
mergedData$Special.Notes[grepl("^Fiscal year end: June 30", mergedData$Special.Notes)]
length(grep("^Fiscal year end: June 30", mergedData$Special.Notes))
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes <- data.table(sampleTimes)
View(sampleTimes)
?POSIXlt
?grep
sampleTimes12 <- grep("^2012", sampleTimes)
sampleTimes12 <- sampleTimes[grep("^2012", sampleTimes)]
View(sampleTimes12)
?wday
sapply(sampleTimes12, wday)
sampleTimes12Mon <- sapply(sampleTimes12, wday)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
View(sampleTimes12Mon)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(..., label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(... , label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday(label = TRUE)))
sampleTimes12Mon <- data.table(sapply(sampleTimes12, wday))
wday(sampleTimes12Mon, label = TRUE)
sampleTimes12Mon <- data.table(sapply(sampleTimes12, weekdays))
View(sampleTimes12Mon)
?n
MOndays <- length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon)])
MOndays
length(sampleTimes12Mon[grepl("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon[grep("segunda-feira", sampleTimes12Mon$sampleTimes)])
length(sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes)))
sampleTimes12Mon(grep("segunda-feira", sampleTimes12Mon$sampleTimes))
length(which(wday(sampleTimes12Mon, label = T) == "segunda-feira"))
length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays <- length(which(sampleTimes12Mon$sampleTimes == "segunda-feira"))
Mondays
36.92/6
library(ggplot2)
testdat <- data.frame(x = 1:100, y = rnorm(100))
plot(testdat$x, testdat$y, type = 'l', ylim = c(-3,3))
testdat[50,2] <- 100
plot(testdat$x, testdat$y, type = 'l', ylim = c(-3,3))
library(ggplot2)
g <- ggplot(testdat, aes(x = x, y = y))
g + geom_line()
g + geom_line + ylim(-3,3)
g + geom_line() + ylim(-3,3)
g + geom_line() + coord_cartesian(ylim = c(3,-3))
set.seed(12345)
par(mar = rep (0.2, 4))
dataMatrix <- matrix(rnorm(400), nrow = 40)
image(1:10, 1:40, t(dataMatrix)[,nrow(dataMatrix):1])
par(mar = rep(0.2, 4))
heatmap(dataMatrix)
set.seed(678910)
set.seed(678910)
for (i in 1:40){
#flip a coin
coinFlip <- rbinom(1, size = 1, prob = 0.5)
# if a coin is heads add a common pattern to the row
if (coinFlip){
dataMatrix[i,] <- dataMatrix[i,] + rep(c(0, 3), each = 5)
}
}
par(mar = rep(0.2, 4))
heatmap(dataMatrix)
image(1:10, 1:40, t(dataMatrix)[,nrow(dataMatrix):1])
heatmap(dataMatrix)
hh <- hclust(dist(dataMatrix))
dataMatrixOrdered <- dataMatrix[hh$order,]
par(mfrow = c(1,3))
image(t(dataMatrixOrdered)[, nrow(dataMatrixOrdered):1])
plot(rowMeans(dataMatrixOrdered), 40:1, xlab = "Row Mean", ylab = "Row", pch = 19)
plot(colMeans(dataMatrixOrdered), xlab = "Column", ylab = "Column Mean", pch = 19)
20.57/1870
install.packages("knitr")
install.packages("kernlab")
library(kernlab)
data(spam)
str(spam)
str(spam[,1:5])
set.seed(3435)
set.seed(3435)
trainIndicator = rbinom(4601, size = 1, prob = 0.5)  # coinflip to select half of the data set
table(trainIndicator)
train$Spam = spam[trainIndicator == 1, ]
trainSpam = spam[trainIndicator == 1, ]
testSpam = spam[trainIndicator == 0, ]
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
plot((trainSpam$capitalAve ~ trainSpam$type))
plot((trainSpam$capitalAve ~ trainSpam$type))
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type) # capitalAve = averaga number of capital letters
plot(log10(trainSpam[,1:4]+1))
hCluster = hclust(dist(t(trainSpam[,1:57])))
plot(hCluster)
hClusterUpdated = hclust(dist(t(log10(trainSpam[,1:57]+1))))
plot(hClusterUpdated)
hClusterUpdated = hclust(dist(t(log10(trainSpam[,1:55]+1))))
plot(hClusterUpdated)
trainSpam$numType = as.numeric(trainSpam$type) - 1
library(boot)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x, y) sum(x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmfit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmfit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
prodictedSpam[predictionModel$fitted > 0.5 ] = "spam"
predictedSpam[predictionModel$fitted > 0.5 ] = "spam"
table(predictedSpam, testSpam$type)
(61+449)/(1346 + 61 + 458 + 449)
(61+458)/(1346 + 61 + 458 + 449)
595/548
567/595
567/549
567/548
502/513
1-0.978
481/502
481/513
setwd("C:/Users/Marcelo/Desktop/Data/B2WLabs/")
rm(list = ls())
library(ggplot2)
P2_sales_by_weekday_month <- read.csv("P2_sales_by_weekday_month.csv",
header = TRUE, stringsAsFactors = FALSE)
P2_sales_by_weekday_month$PROD_ID <- NULL
ggplot(P2_sales_by_weekday_month, aes(x = 1:70, y = QTY_ORDER))+
geom_point(data = P2_sales_by_weekday_month, aes(group = day, color = factor(month)), size = 3)+
geom_smooth()+
geom_line(data = P2_sales_by_weekday_month, aes(group = month, color = factor(month)))+
xlab("Dias da Semana ao longo dos meses")+
ylab("Quantidade vendida Produto 2")
plot(P2_sales_by_weekday_month$Price, P2_sales_by_weekday_month$QTY_ORDER)
plot(P2_sales_by_weekday_month$Price, log(P2_sales_by_weekday_month$QTY_ORDER))
boxplot(log(P2_sales_by_weekday_month$QTY_ORDER)
regP2 <- lm(QTY_ORDER ~ Price, data = P1_sales_by_weekday_month)
summary(regP1)
# r^2 = 0.40
P2 <- read.csv("PROD_2.csv", sep = " ", header = TRUE, stringsAsFactors = FALSE)
# Correlation
cor(log(P2$QTY_ORDER), log(P2$Price))
# Inverse correlation, increasing the price, quantity sold decreases
# Plot
plot(log(P2$Price), log(P2$QTY_ORDER))
regp2 <- lm(log(P2$QTY_ORDER) ~ log(P2$Price), data = P2)
plot(log(P2$Price), log(P2$QTY_ORDER))
abline(regp2)
# Model P2
#normalizing data
data_P2 <- P2[,3:5]
maxs <- apply(data_P2, 2, max)
mins <- apply(data_P2, 2, min)
P2_scaled <- as.data.frame(scale(data_P2, center = mins, scale = maxs - mins))
b <- maxs - mins
a <- mins
plot(P2_scaled$Price, P2_scaled$QTY_ORDER)
names(P2_scaled)
feats <- names(P2_scaled)[2:3]
f <- paste(feats, collapse = " + ")
f <- as.formula(paste("QTY_ORDER ~", f))
f
library(neuralnet)
library(caTools)
# Split fulldata into train and test
split = sample.split(P2_scaled$Price, SplitRatio = 0.80)
train_nn <- subset(P2_scaled, split == TRUE)
val_nn <- subset(P2_scaled, split == FALSE)
nn <- neuralnet(f, train_nn, hidden = 5, linear.output = FALSE)
plot(nn)
# Compute predictions
predicted <- compute(nn, val_nn[2:3])
print(head(predicted$net.result))
results <- as.data.frame(cbind(val_nn, predicted$net.result))
error <- val_nn$QTY_ORDER - predicted$net.result
RMSE <- rmse(error)
RMSE
# r2 validation sample
rdois <- lm(QTY_ORDER ~ predicted$net.result, data = results)
summary(rdois)$r.squared
plot(results$QTY_ORDER, predicted$net.result)
abline(0,1, col = "red")
plot(density(resid(rdois)))
ggplot(results, aes(x = Price, y = QTY_ORDER))+
geom_point()+
geom_point(aes(y = predicted$net.result), col = "red")
# re-scale data
# backscaled <- P2_scaled * rep(b, each = nrow(P2_scaled)) + rep(a, each = nrow(P2_scaled))
vall_rescaled <- val_nn* rep(b, each = nrow(val_nn)) + rep (a, each = nrow(val_nn))
results_sc <- cbind(predicted$net.result, val_nn[2:3])
results_sc <-  results_sc*rep(b, each = nrow(results_sc)) + rep (a, each = nrow(results_sc))
results_scaled <- as.data.frame(cbind(vall_rescaled, results_sc[1]))
names(results_scaled) <- c("QTY_ORDER", "REVENUE", "PRICE", "ANN_QTY")
error <- results_scaled$QTY_ORDER - results_scaled$ANN_QTY
RMSE <- rmse(error)
RMSE
# r2 validation sample
rdois <- lm(results_scaled$QTY_ORDER ~ results_scaled$ANN_QTY, data = results_scaled)
summary(rdois)$r.squared
plot(results_scaled$QTY_ORDER ~ results_scaled$ANN_QTY)
abline(0,1, col = "red")
library(ggplot2)
ggplot(results_scaled, aes(x = PRICE, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = ANN_QTY), col = "red")
boxplot(log(P2_sales_by_weekday_month$QTY_ORDER))
plot(P2_sales_by_weekday_month$Price, log(P2_sales_by_weekday_month$QTY_ORDER))
View(P2_sales_by_weekday_month)
install.packages("outliers")
P2_sales_out <- rm.outlier(P2_sales_by_weekday_month, fill = TRUE, median = FALSE, opposite = FALSE)
library(outliers)
P2_sales_out <- rm.outlier(P2_sales_by_weekday_month, fill = TRUE, median = FALSE, opposite = FALSE)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
library(caTools)
out <- P2_sales_by_weekday_month$Price < 4.5
P2_sales_out = P2_sales_by_weekday_month[,out]
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
P2_sales_out <- P2_sales_by_weekday_month[,out]
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
View(P2_sales_out)
P2_sales_out <- P2_sales_by_weekday_month[out]
P2_sales_out <- P2_sales_by_weekday_month[out,]
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 4.5)
View(P2_sales_out)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 5)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
plot(P2_sales_out$Price, P2_sales_out$QTY_ORDER)
log(4000)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 5 & < 8.0)
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 5, log(QTY_ORDER) < 8.0)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 5, log(QTY_ORDER) < 8.0)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
P2_sales_out <- subset(P2_sales_by_weekday_month, log(QTY_ORDER) > 5 & log(QTY_ORDER) < 8.0)
plot(P2_sales_out$Price, log(P2_sales_out$QTY_ORDER))
plot(P2_sales_out$Price, P2_sales_out$QTY_ORDER)
regP2 <- lm(QTY_ORDER ~ Price, data = P2_sales_out)
summary(regP2)
cor(P2_sales_out$QTY_ORDER, P2_sales_out$Price)
library(e1071)
set.seed(12345)
split = sample.split(P2_sales_out$Price, SplitRatio = 0.75)
train <- subset(P2_sales_out, split == TRUE)
val <- subset(P2_sales_out, split == FALSE)
names(P2_sales_out)
feats <- names(P2_sales_out)[-(3)]
f <- paste(feats, collapse = " + ")
f <- as.formula(paste("QTY_ORDER ~", f))
f
feats <- names(P2_sales_out)[-(4)]
f <- paste(feats, collapse = " + ")
f <- as.formula(paste("QTY_ORDER ~", f))
f
feats <- names(P2_sales_out)[-(3:4)]
f <- paste(feats, collapse = " + ")
f <- as.formula(paste("QTY_ORDER ~", f))
f
model_svm <- svm(f, data = train, scale = TRUE, kernel = 'radial',
cachesize = 1600, cross = 5, epsilon = 0.1)
svm_val <- predict(model_svm, val)
results_svm <- as.data.frame(cbind(val, svm_val))
RMSE_SVM <-  sqrt(mean(results_svm$QTY_ORDER - svm_val)^2)
RMSE_SVM
summary(model_svm)
rdois_svm <- lm(QTY_ORDER ~ svm_val, data = results_svm)
summary(rdois_svm)$r.squared
ggplot(results_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = results_svm$svm_val), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
svm_full <- predict(model_svm, P2_sales_out)
full_results_svm <- as.data.frame(cbind(P2_sales_out, svm_full))
RMSE_SVM <-  sqrt(mean(full_results_svm$QTY_ORDER - svm_full)^2)
RMSE_SVM
rdois_2 <- lm(QTY_ORDER ~ svm_full, data = full_results_svm)
summary(rdois_2)$r.squared
ggplot(full_results_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = full_results_svm$svm_full), col = "red")+
xlab("Preço")+
ylab("Quantidade P1")
ggplot(full_results_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = full_results_svm$svm_full), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
tuned_model_svm <- tune(svm, f, data = train, scale = TRUE, kernel = 'radial',
cachesize = 2000, ranges = list(epsilon = seq(0.01,0.2,0.01),
cost = 2^(2:9)))
print(tuned_model_svm)
plot(tuned_model_svm)
tuned_model_svm <- tune(svm, f, data = train, scale = TRUE, kernel = 'radial',
cachesize = 2000, ranges = list(epsilon = seq(0.01,0.4,0.01),
cost = 2^(2:9)))
print(tuned_model_svm)
plot(tuned_model_svm)
summary(tuned_model_svm)
tuned_model_P2 <- tuned_model_svm$best.model
summary(tuned_model_P2)
tuned_svm_val <- predict(tuned_model_P2, val)
results_tuned_svm <- as.data.frame(cbind(val, tuned_svm_val))
RMSE_SVM <-  sqrt(mean(results_tuned_svm$QTY_ORDER - tuned_svm_val)^2)
RMSE_SVM
rdois_tuned_svm_te <- lm(QTY_ORDER ~ tuned_svm_val, data = results_tuned_svm)
summary(rdois_tuned_svm_te)$r.squared
ggplot(rdois_tuned_svm_te, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = rdois_tuned_svm_te$results_tuned_svm), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
ggplot(results_tuned_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = results_tuned_svm$results_tuned_svm), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
View(results_tuned_svm)
ggplot(results_tuned_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = results_tuned_svm$tuned_svm_val), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
tuned_svm_full <- predict(tuned_model_P2, P2_sales_out)
full_results_tuned_svm <- as.data.frame(cbind(P2_sales_out, tuned_svm_full))
RMSE_SVM <-  sqrt(mean(full_results_tuned_svm$QTY_ORDER - tuned_svm_full)^2)
RMSE_SVM
rdois_2_full <- lm(QTY_ORDER ~ tuned_svm_full, data = full_results_tuned_svm)
summary(rdois_2_full)$r.squared
ggplot(full_results_tuned_svm, aes(x = Price, y = QTY_ORDER))+
geom_point(size = 4)+
geom_point(aes(y = full_results_tuned_svm$tuned_svm_full), col = "red")+
xlab("Preço")+
ylab("Quantidade P2")
